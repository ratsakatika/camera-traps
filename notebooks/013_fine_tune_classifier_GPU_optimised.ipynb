{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU name: NVIDIA A100-SXM4-40GB (4 available)\n",
      "Host name:  gpuhost001.jc.rl.ac.uk\n",
      "User name:  trr26\n",
      "GPU 0 free memory: 31.97 GiB\n",
      "GPU 1 free memory: 38.56 GiB\n",
      "GPU 2 free memory: 38.56 GiB\n",
      "GPU 3 free memory: 38.56 GiB\n",
      "Using GPU: 3\n",
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading images to GPU: 100%|██████████| 17336/17336 [36:26<00:00,  7.93it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading images to GPU: 100%|██████████| 3669/3669 [11:32<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Validation Loss: 0.35707510428695494, Initial Validation Accuracy: 91.16925592804579%\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:33<00:00,  1.98it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.22024896902090618, Validation Loss: 0.25267313871097385, Validation Accuracy: 92.12319433088035%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:31<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:26<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 0.07666246296074998, Validation Loss: 0.2770420901980327, Validation Accuracy: 92.5320250749523%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:43<00:00,  1.92it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 0.053731832943463224, Validation Loss: 0.30345335408536533, Validation Accuracy: 92.259471245571%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 0.04143187188444791, Validation Loss: 0.2832480655672755, Validation Accuracy: 93.7857726901063%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 0.02588538914914926, Validation Loss: 0.2582714545701848, Validation Accuracy: 94.19460343417825%\n",
      "Model saved to ../models/2024-05-25-14-57-46-deepfaune-finetuned-epochs5-lr1e-05.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:41<00:00,  1.59it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:30<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 1, Train Loss: 0.04615950358545492, Validation Loss: 0.3169180580244005, Validation Accuracy: 92.83183428727173%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:27<00:00,  1.65it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:27<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 2, Train Loss: 0.023872527125842674, Validation Loss: 0.2771166227165573, Validation Accuracy: 93.54047424366313%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:11<00:00,  1.74it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:26<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 3, Train Loss: 0.014429134706919004, Validation Loss: 0.2460505320283435, Validation Accuracy: 94.84873262469338%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:18<00:00,  1.70it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:28<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 4, Train Loss: 0.07224217320746627, Validation Loss: 0.3013495525927283, Validation Accuracy: 93.21340964840556%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:10<00:00,  1.74it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:26<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 5, Train Loss: 0.017780617791924663, Validation Loss: 0.2904463102285777, Validation Accuracy: 94.00381575361133%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:52<00:00,  1.85it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:26<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 6, Train Loss: 0.01167543907671965, Validation Loss: 0.29568716043812976, Validation Accuracy: 94.2491142000545%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:02<00:00,  1.79it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:28<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 7, Train Loss: 0.029326659573286475, Validation Loss: 0.333870319723697, Validation Accuracy: 93.10438811665304%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:21<00:00,  1.68it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:29<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 8, Train Loss: 0.05275589163387533, Validation Loss: 0.34272687848302746, Validation Accuracy: 92.47751430907604%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [05:21<00:00,  1.68it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:26<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 9, Train Loss: 0.014514613297154018, Validation Loss: 0.3318232206764072, Validation Accuracy: 93.40419732897247%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:31<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 10, Train Loss: 0.02071174676099144, Validation Loss: 0.25540221354754267, Validation Accuracy: 94.38539111474516%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:31<00:00,  1.99it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:27<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 11, Train Loss: 0.008840903803002387, Validation Loss: 0.2679339782932758, Validation Accuracy: 94.57617879531207%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [06:04<00:00,  1.49it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:29<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 12, Train Loss: 0.015736363778317747, Validation Loss: 0.3600545950599474, Validation Accuracy: 91.9051512673753%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:56<00:00,  1.83it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:26<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 13, Train Loss: 0.0239962086149727, Validation Loss: 0.40338166666207026, Validation Accuracy: 91.76887435268466%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:47<00:00,  1.89it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 14, Train Loss: 0.023773322177895583, Validation Loss: 0.28857912298272703, Validation Accuracy: 94.4126464976833%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 15, Train Loss: 0.007732784138767626, Validation Loss: 0.2927628387937543, Validation Accuracy: 94.4126464976833%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 16, Train Loss: 0.04051261291414116, Validation Loss: 0.46329555944719925, Validation Accuracy: 89.72472063232489%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 17, Train Loss: 0.010644173093068547, Validation Loss: 0.27159691222971205, Validation Accuracy: 94.54892341237394%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 18, Train Loss: 0.005830461322671586, Validation Loss: 0.31345982527288035, Validation Accuracy: 94.35813573180704%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 19, Train Loss: 0.017597864305531147, Validation Loss: 0.3351692418559295, Validation Accuracy: 93.75851730716816%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 20, Train Loss: 0.015025084544745989, Validation Loss: 0.4068621974920184, Validation Accuracy: 91.85064050149904%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 21, Train Loss: 0.010660814999920649, Validation Loss: 0.34861497379231127, Validation Accuracy: 94.08558190242573%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 22, Train Loss: 0.008634482588686666, Validation Loss: 0.38019896332335795, Validation Accuracy: 92.31398201144727%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 23, Train Loss: 0.025416586718128572, Validation Loss: 0.3532532045321521, Validation Accuracy: 93.21340964840556%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 24, Train Loss: 0.0061646138516099165, Validation Loss: 0.3217790649293499, Validation Accuracy: 94.16734805124013%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 25, Train Loss: 0.020124297714177897, Validation Loss: 0.30434746934665585, Validation Accuracy: 93.86753883892068%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 26, Train Loss: 0.005272617719545055, Validation Loss: 0.33750800008298504, Validation Accuracy: 94.00381575361133%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 27, Train Loss: 0.0042250561296632745, Validation Loss: 0.34130839235650534, Validation Accuracy: 93.84028345598256%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 28, Train Loss: 0.004459403390391314, Validation Loss: 0.34314549614945683, Validation Accuracy: 93.81302807304442%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 29, Train Loss: 0.00419014133395008, Validation Loss: 0.3429097923608701, Validation Accuracy: 94.03107113654947%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 30, Train Loss: 0.004581312163062014, Validation Loss: 0.34553859252380237, Validation Accuracy: 94.0583265194876%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 31, Train Loss: 0.004750180773645697, Validation Loss: 0.33408303040815635, Validation Accuracy: 94.49441264649768%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 32, Train Loss: 0.004364845083445812, Validation Loss: 0.3279630865796603, Validation Accuracy: 94.19460343417825%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 33, Train Loss: 0.052622352593341616, Validation Loss: 0.36640974492187245, Validation Accuracy: 92.94085581902425%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 34, Train Loss: 0.013897899404628166, Validation Loss: 0.3726689679841713, Validation Accuracy: 92.80457890433361%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 35, Train Loss: 0.015035595828142527, Validation Loss: 0.3276033321850738, Validation Accuracy: 93.1588988825293%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 36, Train Loss: 0.01110592156583555, Validation Loss: 0.41784513546747054, Validation Accuracy: 92.09593894794222%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 37, Train Loss: 0.011971177908658672, Validation Loss: 0.34758663390661954, Validation Accuracy: 93.34968656309621%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 38, Train Loss: 0.004212810537413761, Validation Loss: 0.36092654784477457, Validation Accuracy: 93.64949577541564%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 39, Train Loss: 0.020475973197602214, Validation Loss: 0.3305898218898293, Validation Accuracy: 93.64949577541564%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 40, Train Loss: 0.007571281973714845, Validation Loss: 0.37186514586110797, Validation Accuracy: 93.62224039247751%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 41, Train Loss: 0.00824257102365704, Validation Loss: 0.28628237961881553, Validation Accuracy: 94.52166802943582%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 42, Train Loss: 0.013496069107807292, Validation Loss: 0.3614103731447378, Validation Accuracy: 93.34968656309621%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 43, Train Loss: 0.01079075410964538, Validation Loss: 0.42578056366349737, Validation Accuracy: 92.42300354319978%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 44, Train Loss: 0.006333805954974226, Validation Loss: 0.3312187950769533, Validation Accuracy: 94.14009266830199%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 45, Train Loss: 0.0041809465111500715, Validation Loss: 0.31436469634934383, Validation Accuracy: 94.52166802943582%\n",
      "Model saved to ../models/2024-05-25-18-53-26-deepfaune-finetuned-epochs50-lr1e-05.pt\n",
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading images to GPU: 100%|██████████| 3557/3557 [03:33<00:00, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 112/112 [00:23<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.20860275513073%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import InterpolationMode, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import getpass\n",
    "import socket\n",
    "from datetime import datetime\n",
    "\n",
    "# Set the PyTorch device (GPU/cuda or CPU)\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "    device = torch.device(dev)\n",
    "\n",
    "    gpu_name = torch.cuda.get_device_name(torch.device(\"cuda\"))\n",
    "    print(f\"GPU name: {gpu_name} ({torch.cuda.device_count()} available)\")\n",
    "    \n",
    "    print(\"Host name: \", socket.gethostname())  # Retrieve the hostname of the current system to determine the environment\n",
    "    print(\"User name: \", getpass.getuser())  # Retrieve the current user's username\n",
    "\n",
    "    # If the notebook is running on the JASMIN GPU cluster, select the GPU with the most free memory\n",
    "    if socket.gethostname() == \"gpuhost001.jc.rl.ac.uk\":\n",
    "\n",
    "        def select_gpu_with_most_free_memory():\n",
    "            max_memory_available = 0\n",
    "            gpu_id_with_max_memory = 0\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                torch.cuda.set_device(i)\n",
    "                free_mem, total_mem = torch.cuda.mem_get_info(i)\n",
    "                free_mem_gib = free_mem / (1024 ** 3)\n",
    "                free_mem_rounded = round(free_mem_gib, 2)\n",
    "                print(f\"GPU {i} free memory: {free_mem_rounded} GiB\")\n",
    "                if free_mem_gib >= max_memory_available:  # >= biases away from GPU 0, which most JASMIN users default to\n",
    "                    max_memory_available = free_mem_gib\n",
    "                    gpu_id_with_max_memory = i\n",
    "            return gpu_id_with_max_memory\n",
    "\n",
    "        best_gpu = select_gpu_with_most_free_memory()\n",
    "\n",
    "        torch.cuda.set_device(best_gpu)\n",
    "        print(f\"Using GPU: {best_gpu}\")\n",
    "    \n",
    "    else:\n",
    "        _, max_memory = torch.cuda.mem_get_info()\n",
    "        max_memory = max_memory / (1024 ** 3)\n",
    "        print(f\"GPU memory: {max_memory} GiB\")\n",
    "\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "    device = torch.device(dev)\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "gpu_override = False\n",
    "if gpu_override:\n",
    "    torch.cuda.set_device(3)\n",
    "    print(f\"OVERRIDE: Using GPU: {3}\")\n",
    "\n",
    "CROP_SIZE = 182\n",
    "BACKBONE = \"vit_large_patch14_dinov2\"\n",
    "weight_path = \"../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt\"\n",
    "\n",
    "jasmin = True\n",
    "\n",
    "if jasmin:\n",
    "    train_path = \"../data/split_data/train\"\n",
    "    val_path = \"../data/split_data/val\"\n",
    "    test_path = \"../data/split_data/test\"\n",
    "else:\n",
    "    train_path = \"/media/tom-ratsakatika/CRUCIAL 4TB/FCC Camera Trap Data/split_data/train\"\n",
    "    val_path = \"/media/tom-ratsakatika/CRUCIAL 4TB/FCC Camera Trap Data/split_data/val\"\n",
    "    test_path = \"/media/tom-ratsakatika/CRUCIAL 4TB/FCC Camera Trap Data/split_data/test\"\n",
    "\n",
    "ANIMAL_CLASSES = [\"badger\", \"ibex\", \"red deer\", \"chamois\", \"cat\", \"goat\", \"roe deer\", \"dog\", \"squirrel\", \"equid\", \"genet\",\n",
    "                  \"hedgehog\", \"lagomorph\", \"wolf\", \"lynx\", \"marmot\", \"micromammal\", \"mouflon\",\n",
    "                  \"sheep\", \"mustelid\", \"bird\", \"bear\", \"nutria\", \"fox\", \"wild boar\", \"cow\"]\n",
    "\n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None, preload_to_gpu=False):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.preload_to_gpu = preload_to_gpu\n",
    "\n",
    "        for label in os.listdir(directory):\n",
    "            label_dir = os.path.join(directory, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                for image in os.listdir(label_dir):\n",
    "                    image_path = os.path.join(label_dir, image)\n",
    "                    self.images.append(image_path)\n",
    "                    self.labels.append(ANIMAL_CLASSES.index(label))\n",
    "\n",
    "        if self.preload_to_gpu:\n",
    "            self.preload_images()\n",
    "\n",
    "    def preload_images(self):\n",
    "        self.loaded_images = []\n",
    "        for image_path in tqdm(self.images, desc=\"Preloading images to GPU\"):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            self.loaded_images.append(image.to(device))\n",
    "        self.labels = torch.tensor(self.labels, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.preload_to_gpu:\n",
    "            return self.loaded_images[idx], self.labels[idx]\n",
    "        else:\n",
    "            image_path = self.images[idx]\n",
    "            label = self.labels[idx]\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, freeze_up_to_layer=16):\n",
    "        super(Classifier, self).__init__()\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = timm.create_model(BACKBONE, pretrained=False, num_classes=len(ANIMAL_CLASSES), dynamic_img_size=True)\n",
    "        state_dict = torch.load(weight_path, map_location=torch.device(device))['state_dict']\n",
    "        self.model.load_state_dict({k.replace('base_model.', ''): v for k, v in state_dict.items()})\n",
    "\n",
    "        # Freeze layers up to the specified layer\n",
    "        if freeze_up_to_layer is not None:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if self._should_freeze_layer(name, freeze_up_to_layer):\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize(size=(CROP_SIZE, CROP_SIZE), interpolation=InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
    "        ])\n",
    "\n",
    "    def _should_freeze_layer(self, name, freeze_up_to_layer):\n",
    "        if 'blocks' in name:\n",
    "            block_num = int(name.split('.')[1])\n",
    "            if block_num <= freeze_up_to_layer:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict(self, image):\n",
    "        img_tensor = self.transforms(image).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(img_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            top_p, top_class = probabilities.topk(1, dim=1)\n",
    "            return ANIMAL_CLASSES[top_class.item()], top_p.item()\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n",
    "\n",
    "def test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def save_model(model, total_epochs, learning_rate):\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    model_save_path = f\"../models/{now}-deepfaune-finetuned-epochs{total_epochs}-lr{learning_rate}.pt\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f'Model saved to {model_save_path}')\n",
    "\n",
    "def main():\n",
    "    initial_epochs = 5  # Set the number of epochs\n",
    "    batch_size = 32  # Set the batch size\n",
    "    learning_rate = 1e-5  # Reduced learning rate for fine-tuning\n",
    "    total_epochs = initial_epochs\n",
    "    patience = 10  # Early stopping patience\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((CROP_SIZE, CROP_SIZE), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
    "    ])\n",
    "\n",
    "    print('Loading training data...')\n",
    "    train_dataset = AnimalDataset(train_path, transform=transform, preload_to_gpu=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    print('Loading validation data...')\n",
    "    val_dataset = AnimalDataset(val_path, transform=transform, preload_to_gpu=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = Classifier(freeze_up_to_layer=16).to(device)  # Freeze up to the 16th layer\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    # Evaluate validation set before training\n",
    "    print('Initial validation evaluation...')\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "    print(f'Initial Validation Loss: {val_loss}, Initial Validation Accuracy: {val_accuracy}%')\n",
    "\n",
    "    print('Training started...')\n",
    "    for epoch in range(initial_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}%')\n",
    "\n",
    "        # Update the learning rate based on validation loss\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            save_model(model, total_epochs, learning_rate)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Option to continue training\n",
    "    while True:\n",
    "        more_epochs = int(input(\"Enter the number of additional epochs to continue training (0 to stop): \"))\n",
    "        if more_epochs == 0:\n",
    "            break\n",
    "        total_epochs += more_epochs\n",
    "        for epoch in range(more_epochs):\n",
    "            train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "            print(f'Additional Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}%')\n",
    "            \n",
    "            # Update the learning rate based on validation loss\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                save_model(model, total_epochs, learning_rate)\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    # Load test data\n",
    "    print('Loading test data...')\n",
    "    test_dataset = AnimalDataset(test_path, transform=transform, preload_to_gpu=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Test the model\n",
    "    print('Testing the model...')\n",
    "    test_accuracy = test(model, test_loader, device)\n",
    "    print(f'Test Accuracy: {test_accuracy}%')\n",
    "\n",
    "    # Return critical variables for further experimentation\n",
    "    return model, train_loader, val_loader, test_loader, criterion, optimizer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model, train_loader, val_loader, test_loader, criterion, optimizer = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 1, Train Loss: 0.002243481088951251, Validation Loss: 0.32722881228284145, Validation Accuracy: 94.82147724175525%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 2, Train Loss: 0.0022394274977986365, Validation Loss: 0.32746408745008665, Validation Accuracy: 94.82147724175525%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 3, Train Loss: 0.002229393843951057, Validation Loss: 0.32786337191390263, Validation Accuracy: 94.82147724175525%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 4, Train Loss: 0.0022240874828223216, Validation Loss: 0.3283195710445808, Validation Accuracy: 94.8759880076315%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 542/542 [04:30<00:00,  2.00it/s]\n",
      "Validation: 100%|██████████| 115/115 [00:24<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Epoch 5, Train Loss: 0.0022193364509803777, Validation Loss: 0.3285740491295947, Validation Accuracy: 94.8759880076315%\n",
      "Model saved to ../models/2024-05-25-21-00-25-deepfaune-finetuned-epochs60-lr1e-07.pt\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 55\n",
    "learning_rate = 1e-7\n",
    "\n",
    "while True:\n",
    "    more_epochs = int(input(\"Enter the number of additional epochs to continue training (0 to stop): \"))\n",
    "    total_epochs += more_epochs\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    if more_epochs == 0:\n",
    "        break\n",
    "    for epoch in range(more_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "        print(f'Additional Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}%')\n",
    "    save_model(model, total_epochs, learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "- Decreating learning rate below 1e-6 doesn't help\n",
    "- Next step is to look into number of layers frozen\n",
    "- Perhaps unfreeze all, then slowly increase number of frozen layers? Look into best practice\n",
    "- Otherwise augment dataset - but is that the issue? What tests are thereforre this?\n",
    "- Before augmenting dataset, look at loss function for wild boar instead - likely better resutls - i.e. fine tune for wild boar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
