{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Wildlife Alert System: Example Tutorial Notebook\n",
    "Thomas Ratsakatika | AI and Environment Researcher | University of Cambridge\n",
    "\n",
    "Last updated: 26 June 2024\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook will walk you through how to set up and use the advanced version of the wildlife alert system.\n",
    "\n",
    "**Steps 1 and 2** let you experiment with the alert system using photos stored on your computer.\n",
    "\n",
    "**Steps 3 and 4** walk you through setting up the system to receive emails from a 4G-enabled camera trap.\n",
    "\n",
    "If you have any queries or feedback, please contact [Tom Ratsakatika](mailto:trr26@cam.ac.uk)\n",
    "\n",
    "## Step 1: Import Modules and AI Models\n",
    "\n",
    "First, ensure you have cloned (copied) the repository to your device, created a virtual environment and installed the required modules by following the instructions in the [README](../README.md#-example-tutorial).\n",
    "\n",
    "You should then be able to run the cell below, which imports the modules required to run the alert system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import required modules ###\n",
    "\n",
    "from megadetector.detection import run_detector  # MegaDetector object detection model\n",
    "import pandas as pd             # Data manipulation and analysis\n",
    "import yaml                     # Handles YAML (config) files\n",
    "import time                     # Time functions\n",
    "from datetime import datetime   # Date and time manipulation\n",
    "import schedule                 # Schedule function for weekly reports\n",
    "import functools                # Function for weekly reports\n",
    "import sys                      # System parameters and functions\n",
    "sys.path.append('../scripts')   # Add scripts directory to system path\n",
    "\n",
    "### Import modules required for the the example ###\n",
    "\n",
    "from IPython.display import display, HTML  # Function to display images in Jupyter notebooks\n",
    "import tkinter as tk            # Tkinter GUI toolkit\n",
    "from tkinter import filedialog  # File dialog for opening files\n",
    "from PIL import Image           # Python Imaging Library (PIL)\n",
    "import os                       # Functions for interacting with the operating system\n",
    "from io import BytesIO          # Handle binary data in memory\n",
    "import base64                   # Encode binary data for HTML display\n",
    "\n",
    "### Import alert system functions from ../scripts/alert_system_utils.py ###\n",
    "\n",
    "from alert_system_utils import (\n",
    "\n",
    "    ### Functions to download photos and metadata from emails ###\n",
    "\n",
    "    current_time,               # Get the current time\n",
    "    check_emails,               # Checks for new emails, extracts photos and metadata\n",
    "    extract_and_update_camera_info,  # Extract and update camera information\n",
    "    update_camera_data_dataframe,    # Update camera data DataFrame\n",
    "\n",
    "    ### Functions to detect and classify animals in photos ###\n",
    "\n",
    "    set_device,                 # Sets computation device (CPU/GPU)\n",
    "    detector,                   # Animal/human/vehicle detection\n",
    "    classifier,                 # Animal classification model\n",
    "    batch_classification,       # Batch classification of images\n",
    "    detections_in_sequence,     # Checks if anything has been detected\n",
    "\n",
    "    ### Functions to annotate photos and send an alert to Telegram ###\n",
    "\n",
    "    generate_alert_caption,     # Generate captions for alerts\n",
    "    send_alert_to_telegram,     # Send alerts to Telegram\n",
    "    annotate_images,            # Annotate images with detection results\n",
    "\n",
    "    ### Functions to save the photos and send weekly reports ###\n",
    "    save_images,                # Save images to disk\n",
    "    send_weekly_report          # Send a weekly report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can initialise the detection and classification models.\n",
    "\n",
    "The alert system follows a two-stage detection and classification process. The detection model specalises in detecting animals, humans and vehicles in photos, and determining their location with bounding boxes. The classification model specialises in determining the species of animals.\n",
    "\n",
    "This notebook uses MegaDetector for detection and DeepFaune for classification. You can change the path for the classifcation model to one of the fine-tuned [Carpathian Mountains models](../README.md#-models) if required. Changing the paths to any other detection of classification models will require more complex changes to the detector and classifier functions in the [alert system utils](../scripts/alert_system_utils.py). \n",
    "\n",
    "Run the cell below to initialise the detection and classifiaction models. The code will automatically use a NVIDIA GPU if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Model Settings\n",
    "DETECTOR_MODEL_PATH = '../models/md_v5a.0.0.pt'\n",
    "DETECTOR_CLASSES = [\"animal\", \"human\", \"vehicle\"]\n",
    "\n",
    "# Classification Model Settings\n",
    "BACKBONE = 'vit_large_patch14_dinov2'\n",
    "CLASSIFIER_MODEL_PATH = '../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt'   # Change to fine-tuned model if desired\n",
    "CLASSIFIER_CLASSES = [\n",
    "    \"Badger\", \"Ibex\", \"Red Deer\", \"Chamois\", \"Cat\",\n",
    "    \"Goat\", \"Roe Deer\", \"Dog\", \"Squirrel\", \"Equid\", \"Genet\",\n",
    "    \"Hedgehog\", \"Lagomorph\", \"Wolf\", \"Lynx\", \"Marmot\",\n",
    "    \"Micromammal\", \"Mouflon\", \"Sheep\", \"Mustelid\", \"Bird\",\n",
    "    \"Bear\", \"Nutria\", \"Fox\", \"Wild Boar\", \"Cow\"\n",
    "]\n",
    "ROMANIAN_CLASSES = [\n",
    "    \"Bursuc\", \"Ibex\", \"Cerb\", \"Capră Neagră\", \"Pisică\", \n",
    "    \"Capră\", \"Căprioară\", \"Câine\", \"Veveriță\", \"Cal\", \"Genetă\",\n",
    "    \"Arici\", \"Iepuri\", \"Lup\", \"Râs\", \"Marmotă\", \n",
    "    \"Micromamifer\", \"Muflon\", \"Oaie\", \"Mustelid\", \"Pasăre\", \n",
    "    \"Urs\", \"Nutrie\", \"Vulpe\", \"Mistreț\", \"Vacă\"\n",
    "]\n",
    "SPECIES_OF_INTEREST = [\"Wild Boar\", \"Bear\"] # Species for which priority alerts are sent (currently only supports wild boar and bears)\n",
    "\n",
    "# Locations of capture database, camera location tables, and storage folder for photos received by the alert system\n",
    "CAPTURE_DATABASE_PATH = '../data/capture_database.csv' \n",
    "CAMERA_LOCATIONS_PATH = '../data/camera_locations.csv'\n",
    "PHOTOS_PATH = '../data/photos/'\n",
    "\n",
    "# Initialise the Detection and Classifier Models\n",
    "device = set_device()\n",
    "detector_model = run_detector.load_detector(DETECTOR_MODEL_PATH)\n",
    "print(\"Loading classifier...\")\n",
    "start_time = time.time()\n",
    "classifier_model = classifier(CLASSIFIER_MODEL_PATH, BACKBONE, CLASSIFIER_CLASSES, device)\n",
    "end_time = time.time()\n",
    "print(f\"Loaded classifier in {(end_time - start_time):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test Your Setup on Example Photos\n",
    "\n",
    "Before testing the system on some photos, we need to set the models' thresholds. These can be set between 0 and 1.\n",
    "\n",
    "A lower **detection** threshold will mean the system is more sensitive, but it might think that objects such as log or a tree stump are animals when they are not. A higher detection threshold will mean that you get fewer false positives, but the system may miss difficult to detect animals (e.g. nighttime or blurry images).\n",
    "\n",
    "A lower **classification** threshold will mean that the system will be more likely to try and classify an animal detection, even if it isn't sure. A higher classification threshold will mean that the model will label more animal detections as \"unknown\".\n",
    "\n",
    "We also need to set the alert system language (currently English or Romanian), and the times during which we want to receive photos of people or vehicles. The latter is a privacy feature, to prevent the system from sending photos of the general public during daylight hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_THRESHOLD = 0.15      # Detection threshold - recommended 0.15\n",
    "CLASSIFICATION_THRESHOLD = 0.20 # Classification threshold - recommend set between 0.2 to 0.8 depending on tolerance for false positives\n",
    "\n",
    "# Alert Message Settings\n",
    "ALERT_LANGUAGE = \"en\"           # Curently English (en) and Romanian (ro) are supported\n",
    "HUMAN_ALERT_START = \"21:00\"     # Privacy feature: start/end time that photos of people may be sent\n",
    "HUMAN_ALERT_END = \"06:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can run the cell below to run the system on a photo(s) on your device. Note how the first detects the number of objects, and then itterates through each detection in each photo using the classifier.\n",
    "\n",
    "You can select more than one photo by holding down CTRL and click on multiple files. This mimics how the alert system may receive photos from a 4G camera trap in the field. *Note that the system does not expect to see bears and wild boars together, so if you select both, it will only count the first species it sees in the alert message header.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open file dialog and select one or more JPG images\n",
    "def open_images():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    root.geometry(\"800x600\")  \n",
    "    initial_dir = '../data/example_photos'  # Set initial directory for file dialog\n",
    "    # Open file dialog to select one or more JPG files\n",
    "    file_paths = filedialog.askopenfilenames(initialdir=initial_dir, title=\"Select file(s)\",\n",
    "                                             filetypes=[(\"JPEG files\", \"*.jpg\"), \n",
    "                                                        (\"JPEG files\", \"*.jpeg\"), \n",
    "                                                        (\"JPEG files\", \"*.JPG\"), \n",
    "                                                        (\"JPEG files\", \"*.JPEG\")])\n",
    "    # Open and return the selected images as a list of PIL Image objects\n",
    "    return [Image.open(file_path) for file_path in file_paths] if file_paths else []\n",
    "\n",
    "\n",
    "# Call the function and store the selected images in a list\n",
    "images = open_images()\n",
    "\n",
    "# Print the number of selected images\n",
    "print(f\"{current_time()} | {len(images)} image(s) selected\")\n",
    "\n",
    "# Load the capture database into a DataFrame, df\n",
    "# This DataFrame is required to manage data in the subsequent steps\n",
    "df = pd.read_csv(CAPTURE_DATABASE_PATH)\n",
    "\n",
    "# Loop to add dummy rows to the DataFrame for this example\n",
    "for _ in range(len(images)):\n",
    "    new_row = pd.DataFrame([['Example', 1] + ['Example'] * 10 + [None] * (len(df.columns) - 12)], columns=df.columns)\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# Detect animals, humans and/or vehicles in the image(s) using the MegaDetector detection model\n",
    "df, human_warning = detector(df, detector_model, images, DETECTION_THRESHOLD)\n",
    "\n",
    "# Classify objects in the image(s) using the DeepFaune classification model\n",
    "df = batch_classification(df, classifier_model, images, CLASSIFICATION_THRESHOLD)\n",
    "\n",
    "# Check if there are any detections in the sequence above the threshold\n",
    "if detections_in_sequence(df, images):\n",
    "    # Generate an alert caption based on the detections\n",
    "    df, alert_caption = generate_alert_caption(df, human_warning, HUMAN_ALERT_START, HUMAN_ALERT_END, len(images), SPECIES_OF_INTEREST, \"example@email.com\", ALERT_LANGUAGE, CLASSIFIER_CLASSES, ROMANIAN_CLASSES)\n",
    "    human_warning = False  # Reset human warning flag\n",
    "    # Annotate images with bounding boxes, labels and confidence levels\n",
    "    images = annotate_images(df, images, human_warning, HUMAN_ALERT_START, HUMAN_ALERT_END, ALERT_LANGUAGE, CLASSIFIER_CLASSES, ROMANIAN_CLASSES)\n",
    "\n",
    "# Display the images in Jupyter notebook\n",
    "if images:\n",
    "    html = \"<div style='display: flex; flex-wrap: wrap;'>\"\n",
    "    for img in images:\n",
    "        buffered = BytesIO()\n",
    "        img.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "        html += f\"<div style='margin: 10px;'><img src='data:image/jpeg;base64,{img_str}' width='600px' /></div>\"\n",
    "    html += \"</div>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "# Display the alert message in Jupyter notebook\n",
    "alert_html = f\"<div style='padding: 10px; background-color: white; border: 1px solid black; white-space: pre-wrap; color: black; width: 600px;'>{alert_caption}</div>\"\n",
    "display(HTML(alert_html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set Up an Alert System Email Account and Telegram Group\n",
    "\n",
    "\n",
    "### Email Setup\n",
    "\n",
    "To set up the system so that it can receive emails from a 4G camera trap, you need to create a dedicated email account to receive the camera trap images. Your email provider **must** support app passwords (e.g. <a href=\"https://myaccount.google.com/apppasswords\" target=\"_blank\">Gmail</a>). Create an app password and keep a record of it. Then set up your 4G camera trap to send photos to this dedicated email address.\n",
    "\n",
    "### Telegram Setup\n",
    "\n",
    "Setup Telegram on your mobile device. Create a bot in Telegram using @BotFather and note down the bot token. Detailed instructions on how to do this can be <a href=\"https://core.telegram.org/bots/tutorial\" target=\"_blank\">found here</a>.\n",
    "\n",
    "Create a group in Telegram, add the bot to the group and make it an admin. Then note down the group's <a href=\"https://www.wikihow.com/Know-Chat-ID-on-Telegram-on-Android\" target=\"_blank\">chat ID</a> (do this AFTER adding the bot - the chat ID should start with '#-100')\n",
    "\n",
    "### Update the Config.yaml file\n",
    "\n",
    "Open the [config.yaml](../config.yaml) file in a text editor. It should be in this format.\n",
    "\n",
    "```\n",
    "imap_config:\n",
    "  host: 'YOUR_IMAP_SERVER_NAME'\n",
    "  user: 'YOUR_DEDICATED_EMAIL_ADDRESS'\n",
    "  password: 'YOUR_APP_PASSWORD'\n",
    "\n",
    "telegram_config:\n",
    "  bot_token: 'YOUR_BOT_TOKEN'\n",
    "  chat_id: 'YOUR_CHAT_ID'\n",
    "\n",
    "smtp_config:\n",
    "  host: 'YOUR_SMTP_SERVER_NAME'\n",
    "  port: 'YOUR_SMTP_SERVER_PORT'\n",
    "  user: 'YOUR_DEDICATED_EMAIL_ADDRESS'\n",
    "  password: 'YOUR_APP_PASSWORD'\n",
    "  recipients:\n",
    "    - 'RECIPIENT_EMAIL_ADDRESS_1'\n",
    "    - 'RECIPIENT_EMAIL_ADDRESS_2'\n",
    "```\n",
    "\n",
    "Update the settings with your email providers imap and smtp settings, and your Telegram bot token and chat ID.\n",
    "\n",
    "The 'recipients' under smtp_config are the email addresses that will receive a regular report. You can change when and how often the regular report is sent in the next cell.\n",
    "\n",
    "**DO NOT share your config.yaml file with anyone as it contains passwords necessary to access your dedicated email account.**\n",
    "\n",
    "### Update the camera(s) details\n",
    "\n",
    "Update the [camera locations](data/camera_locations.csv) CSV file with your camera(s) details, location and a google maps link.\n",
    "\n",
    "You can add as many cameras as you like.\n",
    "\n",
    "### Load your configuration\n",
    "\n",
    "Run the cell below to load your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load settings from configuration file\n",
    "with open('../config.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "IMAP_HOST = config['imap_config']['host']\n",
    "EMAIL_USER = config['imap_config']['user']\n",
    "EMAIL_PASS = config['imap_config']['password']\n",
    "\n",
    "TELEGRAM_BOT_TOKEN = config['telegram_config']['bot_token']\n",
    "TELEGRAM_CHAT_ID =  '-1002249589791' # config['telegram_config']['chat_id']  #  replace with config after tests # \n",
    "\n",
    "SMTP_SERVER = config['smtp_config']['host']\n",
    "SMTP_PORT = int(config['smtp_config']['port'])\n",
    "EMAIL_SENDER = config['smtp_config']['user']\n",
    "EMAIL_PASSWORD = config['smtp_config']['password']\n",
    "RECIPIENTS = config['smtp_config']['recipients']\n",
    "\n",
    "CHECK_EMAIL_FREQUENCY = 60      # Sets how often the system checks for emails (default - 60 seconds)\n",
    "\n",
    "### Settings for regular report (default - weekly on Mondays at 08:00)\n",
    "schedule.every().monday.at(\"08:00\").do(\n",
    "    functools.partial(send_weekly_report, SMTP_SERVER, EMAIL_SENDER, EMAIL_PASSWORD, SMTP_PORT, CAPTURE_DATABASE_PATH, CAMERA_LOCATIONS_PATH, RECIPIENTS, EMAIL_USER)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test the System\n",
    "\n",
    "You can now run the cell below to launch the alert system.\n",
    "\n",
    "The code will check the email account every 60 seconds for unread emails, download any photos, detect and classify animals, and send an alert your Telegram Group.\n",
    "\n",
    "It will then update the [capture database](data/capture_database.csv) and save the original photos in the [photos folder](data/photos).\n",
    "\n",
    "A high level process flow diagramme is shown below the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"\\n{current_time()} | Monitoring {EMAIL_USER} for new messages...\")\n",
    "    while True:\n",
    "        try:\n",
    "            # Check for emails, extract metadata\n",
    "            images, original_images, camera_id, temp_deg_c, img_date, img_time, battery, sd_memory = \\\n",
    "                check_emails(IMAP_HOST, EMAIL_USER, EMAIL_PASS)\n",
    "            \n",
    "            if camera_id:\n",
    "                \n",
    "                # Get the camera details from the camera_location databse\n",
    "                camera_make, gps, location, map_url, battery, sd_memory = extract_and_update_camera_info(CAMERA_LOCATIONS_PATH, camera_id, battery, sd_memory)\n",
    "                \n",
    "                if images:\n",
    "                    \n",
    "                    # If images are attached to the email, open the capture_database\n",
    "                    df = pd.read_csv(CAPTURE_DATABASE_PATH)\n",
    "                    \n",
    "                    # Update the capture database with rows for each image\n",
    "                    df = update_camera_data_dataframe(df, len(images), camera_id, camera_make, img_date, img_time, temp_deg_c, battery, sd_memory, location, gps, map_url)\n",
    "                    \n",
    "                    # Run the detection model on each image\n",
    "                    df, human_warning = detector(df, detector_model, images, DETECTION_THRESHOLD)\n",
    "                    \n",
    "                    # Run the classification model on each image\n",
    "                    df = batch_classification(df, classifier_model, images, CLASSIFICATION_THRESHOLD)\n",
    "                    \n",
    "                    if detections_in_sequence(df, images):\n",
    "                        \n",
    "                        # If there are any detections above the threshold, create an alert caption\n",
    "                        df, alert_caption = generate_alert_caption(df, human_warning, HUMAN_ALERT_START, HUMAN_ALERT_END, len(images), SPECIES_OF_INTEREST, EMAIL_USER, ALERT_LANGUAGE, CLASSIFIER_CLASSES, ROMANIAN_CLASSES)                        \n",
    "                        \n",
    "                        # If no humans/vehicles are detected, annotate the photos with boxes and species labels\n",
    "                        alert_images = annotate_images(df, images, human_warning, HUMAN_ALERT_START, HUMAN_ALERT_END, ALERT_LANGUAGE, CLASSIFIER_CLASSES, ROMANIAN_CLASSES)\n",
    "                        \n",
    "                        # Send an alert to the Telegram group\n",
    "                        send_alert_to_telegram(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, alert_images, alert_caption)\n",
    "                    \n",
    "                    else:\n",
    "                        \n",
    "                        print(f\"{current_time()} | All photos in sequence are empty\")\n",
    "                    \n",
    "                    # Save the original photos the the ../data/photos/ folder\n",
    "                    df = save_images(df, original_images, human_warning, PHOTOS_PATH)\n",
    "                    \n",
    "                    # Update the capture_database\n",
    "                    df.to_csv(CAPTURE_DATABASE_PATH, index=False)\n",
    "                    print(f\"{current_time()} | Capture database updated: {CAPTURE_DATABASE_PATH}\")\n",
    "                    \n",
    "                    # Clear the dataframe to free up memory\n",
    "                    del df\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    print(f\"{current_time()} | No images attached to email\")\n",
    "                \n",
    "                print(f\"\\n{current_time()} | Monitoring {EMAIL_USER} for new messages...\")\n",
    "            \n",
    "            else:\n",
    "                # Wait before checking emails again\n",
    "                time.sleep(CHECK_EMAIL_FREQUENCY)\n",
    "            \n",
    "            # Check to see if it is time to send the regular report\n",
    "            schedule.run_pending()\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"{current_time()} | Interrupted by user\")\n",
    "            break\n",
    "        \n",
    "        # Error handling to keep the system running if an error occurs\n",
    "        except Exception as e:\n",
    "            print(f\"{current_time()} | An error occurred: {e}\")\n",
    "            time.sleep(CHECK_EMAIL_FREQUENCY)\n",
    "            print(f\"\\n{current_time()} | Monitoring {EMAIL_USER} for new messages...\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flow Diagram](../assets/final_alert_system_flow_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Deploy Your Script\n",
    "\n",
    "That's it. The code in this notebook is identical to the [advanced_alert_system.py](scripts/advanced_alert_system.py) script, which you can now edit to align with your required settings.\n",
    "\n",
    "You need to run the [advanced_alert_system.py](../scripts/advanced_alert_system.py) script on a device that can be left on constantly. This may be an old computer or a virtual machine on your server. Consult your IT team to determine the best option.\n",
    "\n",
    "You could alternatively run the [basic_alert_system.py](../scripts/basic_alert_system.py) script on a Raspberry Pi 4B. The logic is similar to this advanced system, however the models and messages are simpler. A Raspberry Pi 5 may even be able to run the advanced version, although this has not been tested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
