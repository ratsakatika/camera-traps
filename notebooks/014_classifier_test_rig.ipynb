{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF vs DF_FineTune\n",
    "\n",
    "- Use validation set to report results\n",
    "- Note these are two different experiments with two different datasets\n",
    "\n",
    "- With megadetector created val/test set, test DF-fine-tuned:\n",
    "    - Dataset where megadetector detected an animal\n",
    "    - Pass through all non-empty. If human/vehicle, set confidence interval for classification higher?\n",
    "    - Precision/recall/F1 for all species, plus total\n",
    "    - 5 epochs, lr1e-5\n",
    "    - 5 epochs, lr1e-5 & 5 epochs, wb loss\n",
    "\n",
    "- Steps\n",
    "    - load val and test set into data loader/transform\n",
    "    - initialise models:\n",
    "        - DeepFaune\n",
    "        - FineTuned\n",
    "    - Get predictions, put in excel table\n",
    "    - Analyse results\n",
    "        - Precision/recall/F1\n",
    "        - by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import getpass\n",
    "import torch\n",
    "import timm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define constants\n",
    "ANIMAL_CLASSES = [\"badger\", \"ibex\", \"red deer\", \"chamois\", \"cat\", \"goat\", \"roe deer\", \"dog\", \"squirrel\", \"equid\", \"genet\",\n",
    "                  \"hedgehog\", \"lagomorph\", \"wolf\", \"lynx\", \"marmot\", \"micromammal\", \"mouflon\",\n",
    "                  \"sheep\", \"mustelid\", \"bird\", \"bear\", \"nutria\", \"fox\", \"wild boar\", \"cow\"]\n",
    "\n",
    "# Define model paths\n",
    "MODEL_PATHS = [\n",
    "    \"../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt\",\n",
    "    \"../models/Boar Balanced PrecisionRecall - 96.8-98.7-deepfaune-finetuned-epochs-15-lr-1e-05-wbpenalty-0for5,10for5,0for5.pt\",\n",
    "    \"../models/Best Oveall Loss Model - deepfaune-finetuned-3epochs-lr1e-5.pt\"\n",
    "]\n",
    "\n",
    "# Define data paths\n",
    "VAL_DIR = \"../data/split_data/val\"\n",
    "TEST_DIR = \"../data/split_data/test\"\n",
    "\n",
    "# Set the PyTorch device (GPU/cuda or CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name()\n",
    "    print(f\"GPU name: {gpu_name} ({torch.cuda.device_count()} available)\")\n",
    "    print(\"Host name: \", socket.gethostname())\n",
    "    print(\"User name: \", getpass.getuser())\n",
    "\n",
    "    if socket.gethostname() == \"gpuhost001.jc.rl.ac.uk\":\n",
    "        def select_gpu_with_most_free_memory():\n",
    "            max_memory_available = 0\n",
    "            gpu_id_with_max_memory = 0\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                torch.cuda.set_device(i)\n",
    "                free_mem, total_mem = torch.cuda.mem_get_info()\n",
    "                free_mem_gib = free_mem / (1024 ** 3)\n",
    "                free_mem_rounded = round(free_mem_gib, 2)\n",
    "                print(f\"GPU {i} free memory: {free_mem_rounded} GiB\")\n",
    "                if free_mem_gib >= max_memory_available:\n",
    "                    max_memory_available = free_mem_gib\n",
    "                    gpu_id_with_max_memory = i\n",
    "            return gpu_id_with_max_memory\n",
    "\n",
    "        best_gpu = select_gpu_with_most_free_memory()\n",
    "        torch.cuda.set_device(best_gpu)\n",
    "        print(f\"Using GPU: {best_gpu}\")\n",
    "    else:\n",
    "        _, max_memory = torch.cuda.mem_get_info()\n",
    "        max_memory = max_memory / (1024 ** 3)\n",
    "        print(f\"GPU memory: {max_memory} GiB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "gpu_override = False\n",
    "if gpu_override:\n",
    "    torch.cuda.set_device(3)\n",
    "    print(f\"OVERRIDE: Using GPU: {3}\")\n",
    "\n",
    "# Define transformations\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((182, 182), interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define Dataset class\n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None, preload_to_gpu=False):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.preload_to_gpu = preload_to_gpu\n",
    "\n",
    "        for label in os.listdir(directory):\n",
    "            label_dir = os.path.join(directory, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                for image in os.listdir(label_dir):\n",
    "                    image_path = os.path.join(label_dir, image)\n",
    "                    self.images.append(image_path)\n",
    "                    self.labels.append(ANIMAL_CLASSES.index(label))\n",
    "\n",
    "        if self.preload_to_gpu:\n",
    "            self.preload_images()\n",
    "\n",
    "    def preload_images(self):\n",
    "        self.loaded_images = []\n",
    "        for image_path in tqdm(self.images, desc=\"Preloading images to GPU\"):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            self.loaded_images.append(image.to(device))\n",
    "        self.labels = torch.tensor(self.labels, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.preload_to_gpu:\n",
    "            return self.loaded_images[idx], self.labels[idx]\n",
    "        else:\n",
    "            image_path = self.images[idx]\n",
    "            label = self.labels[idx]\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, label\n",
    "\n",
    "# Define Classifier class\n",
    "class Classifier:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = timm.create_model('vit_large_patch14_dinov2', pretrained=False, num_classes=len(ANIMAL_CLASSES), dynamic_img_size=True)\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        if 'state_dict' in state_dict:\n",
    "            state_dict = state_dict['state_dict']\n",
    "        if any(k.startswith('model.') for k in state_dict.keys()):\n",
    "            state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "        self.model.load_state_dict({k.replace('base_model.', ''): v for k, v in state_dict.items()})\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, image):\n",
    "        with torch.no_grad():\n",
    "            output = self.model(image.unsqueeze(0))\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            top_p, top_class = probabilities.topk(1, dim=1)\n",
    "            return top_class.item(), top_p.item()\n",
    "\n",
    "# Preload datasets\n",
    "print(\"Loading Validation Set...\")\n",
    "val_dataset = AnimalDataset(VAL_DIR, transform=transforms, preload_to_gpu=True)\n",
    "print(\"Loading Test Set...\")\n",
    "test_dataset = AnimalDataset(TEST_DIR, transform=transforms, preload_to_gpu=True)\n",
    "\n",
    "# Create data loaders\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Function to run inference and store predictions\n",
    "def run_inference_and_store_predictions(model_path, data_loader, dataset_type):\n",
    "    results = {'preds': [], 'probs': [], 'labels': [], 'images': []}\n",
    "    classifier = Classifier(model_path)\n",
    "    \n",
    "    for images, labels in tqdm(data_loader, desc=f\"Running inference on {dataset_type} set with model {model_path}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        for i in range(images.size(0)):\n",
    "            pred_class, pred_prob = classifier.predict(images[i])\n",
    "            results['preds'].append(pred_class)\n",
    "            results['probs'].append(pred_prob)\n",
    "            results['labels'].append(labels[i].item())\n",
    "            results['images'].append(data_loader.dataset.images[i])\n",
    "                \n",
    "    return results\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(results):\n",
    "    y_true = results['labels']\n",
    "    y_pred = results['preds']\n",
    "    \n",
    "    # Filter out classes with no true samples\n",
    "    present_classes = [i for i in range(len(ANIMAL_CLASSES)) if i in y_true or i in y_pred]\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=None, labels=present_classes, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, labels=present_classes, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, labels=present_classes, zero_division=0)\n",
    "    support = np.bincount(y_true, minlength=len(ANIMAL_CLASSES))[present_classes]\n",
    "    \n",
    "    overall_precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'class': [ANIMAL_CLASSES[i] for i in present_classes] + ['overall'],\n",
    "        'precision': np.append(precision, overall_precision),\n",
    "        'recall': np.append(recall, overall_recall),\n",
    "        'f1': np.append(f1, overall_f1),\n",
    "        'support': np.append(support, len(y_true))\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Create empty DataFrames for each model\n",
    "val_metrics_dfs = {}\n",
    "test_metrics_dfs = {}\n",
    "\n",
    "# Iterate over each model and run inference on both validation and test sets\n",
    "for model_path in MODEL_PATHS:\n",
    "    print(f\"Running inference for model: {model_path}\")\n",
    "    \n",
    "    # Run inference on validation set\n",
    "    print(\"Running inference on validation set...\")\n",
    "    val_results = run_inference_and_store_predictions(model_path, val_loader, 'validation')\n",
    "    # Run inference on test set\n",
    "    print(\"Running inference on test set...\")\n",
    "    test_results = run_inference_and_store_predictions(model_path, test_loader, 'test')\n",
    "   \n",
    "    # Calculate and print metrics\n",
    "    print(\"Calculating metrics for validation set...\")\n",
    "    val_metrics = calculate_metrics(val_results)\n",
    "    print(\"Calculating metrics for test set...\")\n",
    "    test_metrics = calculate_metrics(test_results)\n",
    "    \n",
    "    print(f\"\\nMetrics for model {model_path} on validation set:\")\n",
    "    val_metrics_df = pd.DataFrame(val_metrics)\n",
    "    print(val_metrics_df)\n",
    "    print(f\"\\nMetrics for model {model_path} on test set:\")\n",
    "    test_metrics_df = pd.DataFrame(test_metrics)\n",
    "    print(test_metrics_df)\n",
    "    \n",
    "    # Store results in DataFrames for further analysis\n",
    "    val_metrics_dfs[model_path] = val_metrics_df\n",
    "    test_metrics_dfs[model_path] = test_metrics_df\n",
    "\n",
    "# Save all results to a new Excel file for further analysis\n",
    "all_results_file = \"../data/all_model_metrics.xlsx\"\n",
    "print(f\"Saving all results to {all_results_file}...\")\n",
    "with pd.ExcelWriter(all_results_file) as writer:\n",
    "    for model_path in MODEL_PATHS:\n",
    "        val_metrics_df = val_metrics_dfs[model_path]\n",
    "        test_metrics_df = test_metrics_dfs[model_path]\n",
    "        combined_metrics_df = val_metrics_df.join(test_metrics_df.set_index('class'), on='class', rsuffix='_test')\n",
    "        sheet_name = os.path.basename(model_path)\n",
    "        combined_metrics_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "print(\"All results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference for model: ../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt\n",
      "Running inference on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on validation set with model ../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt: 100%|██████████| 3669/3669 [01:17<00:00, 47.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on test set with model ../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt: 100%|██████████| 3557/3557 [01:14<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for validation set...\n",
      "Calculating metrics for test set...\n",
      "\n",
      "Metrics for model ../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt on validation set:\n",
      "          class  precision    recall        f1  support\n",
      "0        badger   0.950000  0.966102  0.957983       59\n",
      "1          ibex   0.000000  0.000000  0.000000        0\n",
      "2      red deer   0.976705  0.928797  0.952149      632\n",
      "3       chamois   0.181818  1.000000  0.307692        4\n",
      "4           cat   0.750000  0.960000  0.842105       25\n",
      "5          goat   0.942623  0.696970  0.801394      165\n",
      "6      roe deer   0.947494  0.894144  0.920046      444\n",
      "7           dog   0.789474  0.913043  0.846774      115\n",
      "8      squirrel   0.129032  1.000000  0.228571        8\n",
      "9         equid   0.671875  0.860000  0.754386       50\n",
      "10        genet   0.000000  0.000000  0.000000        0\n",
      "11    lagomorph   0.652174  1.000000  0.789474       15\n",
      "12         wolf   0.824742  0.930233  0.874317       86\n",
      "13         lynx   0.990521  0.933036  0.960920      224\n",
      "14       marmot   0.000000  0.000000  0.000000        0\n",
      "15  micromammal   0.000000  0.000000  0.000000        0\n",
      "16      mouflon   0.000000  0.000000  0.000000        0\n",
      "17        sheep   0.920000  0.958333  0.938776      240\n",
      "18     mustelid   0.833333  0.967742  0.895522       31\n",
      "19         bird   0.823077  0.869919  0.845850      123\n",
      "20         bear   0.961988  0.934659  0.948127      352\n",
      "21       nutria   0.000000  0.000000  0.000000        0\n",
      "22          fox   0.947853  0.942073  0.944954      328\n",
      "23    wild boar   0.979167  0.935989  0.957091      703\n",
      "24          cow   0.760000  0.584615  0.660870       65\n",
      "25      overall   0.601275  0.691026  0.617080     3669\n",
      "\n",
      "Metrics for model ../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt on test set:\n",
      "          class  precision    recall        f1  support\n",
      "0        badger   0.928571  0.981132  0.954128       53\n",
      "1          ibex   0.000000  0.000000  0.000000        0\n",
      "2      red deer   0.977547  0.915858  0.945698      618\n",
      "3       chamois   0.600000  1.000000  0.750000        3\n",
      "4           cat   0.947368  0.981818  0.964286       55\n",
      "5          goat   0.642857  0.576923  0.608108       78\n",
      "6      roe deer   0.925287  0.958333  0.941520      336\n",
      "7           dog   0.598291  0.693069  0.642202      101\n",
      "8      squirrel   0.100000  1.000000  0.181818        5\n",
      "9         equid   0.880435  0.890110  0.885246      182\n",
      "10        genet   0.000000  0.000000  0.000000        0\n",
      "11     hedgehog   0.000000  0.000000  0.000000        0\n",
      "12    lagomorph   0.611111  1.000000  0.758621       11\n",
      "13         wolf   0.966942  0.928571  0.947368      126\n",
      "14         lynx   1.000000  0.907609  0.951567      184\n",
      "15  micromammal   0.000000  0.000000  0.000000        0\n",
      "16        sheep   0.987342  0.970954  0.979079      241\n",
      "17     mustelid   0.689655  0.952381  0.800000       21\n",
      "18         bird   0.881890  0.925620  0.903226      121\n",
      "19         bear   0.991543  0.891635  0.938939      526\n",
      "20       nutria   0.000000  0.000000  0.000000        0\n",
      "21          fox   0.946328  0.957143  0.951705      350\n",
      "22    wild boar   0.956693  0.941860  0.949219      516\n",
      "23          cow   0.529412  0.900000  0.666667       30\n",
      "24      overall   0.631720  0.723876  0.654975     3557\n",
      "Running inference for model: ../models/Boar Balanced PrecisionRecall - 96.8-98.7-deepfaune-finetuned-epochs-15-lr-1e-05-wbpenalty-0for5,10for5,0for5.pt\n",
      "Running inference on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on validation set with model ../models/Boar Balanced PrecisionRecall - 96.8-98.7-deepfaune-finetuned-epochs-15-lr-1e-05-wbpenalty-0for5,10for5,0for5.pt: 100%|██████████| 3669/3669 [01:17<00:00, 47.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on test set with model ../models/Boar Balanced PrecisionRecall - 96.8-98.7-deepfaune-finetuned-epochs-15-lr-1e-05-wbpenalty-0for5,10for5,0for5.pt: 100%|██████████| 3557/3557 [01:15<00:00, 47.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for validation set...\n",
      "Calculating metrics for test set...\n",
      "\n",
      "Metrics for model ../models/Boar Balanced PrecisionRecall - 96.8-98.7-deepfaune-finetuned-epochs-15-lr-1e-05-wbpenalty-0for5,10for5,0for5.pt on validation set:\n",
      "        class  precision    recall        f1  support\n",
      "0      badger   0.966102  0.966102  0.966102       59\n",
      "1    red deer   0.933642  0.957278  0.945312      632\n",
      "2     chamois   0.666667  0.500000  0.571429        4\n",
      "3         cat   0.956522  0.880000  0.916667       25\n",
      "4        goat   0.777202  0.909091  0.837989      165\n",
      "5    roe deer   0.954545  0.945946  0.950226      444\n",
      "6         dog   0.935185  0.878261  0.905830      115\n",
      "7    squirrel   0.888889  1.000000  0.941176        8\n",
      "8       equid   0.871795  0.680000  0.764045       50\n",
      "9   lagomorph   0.933333  0.933333  0.933333       15\n",
      "10       wolf   0.861702  0.941860  0.900000       86\n",
      "11       lynx   1.000000  0.946429  0.972477      224\n",
      "12      sheep   0.971193  0.983333  0.977226      240\n",
      "13   mustelid   1.000000  0.774194  0.872727       31\n",
      "14       bird   0.943089  0.943089  0.943089      123\n",
      "15       bear   0.966006  0.968750  0.967376      352\n",
      "16        fox   0.932945  0.975610  0.953800      328\n",
      "17  wild boar   0.967922  0.987198  0.977465      703\n",
      "18        cow   0.956522  0.338462  0.500000       65\n",
      "19    overall   0.920172  0.868891  0.884014     3669\n",
      "\n",
      "Metrics for model ../models/Boar Balanced PrecisionRecall - 96.8-98.7-deepfaune-finetuned-epochs-15-lr-1e-05-wbpenalty-0for5,10for5,0for5.pt on test set:\n",
      "        class  precision    recall        f1  support\n",
      "0      badger   0.868852  1.000000  0.929825       53\n",
      "1    red deer   0.963696  0.944984  0.954248      618\n",
      "2     chamois   1.000000  0.666667  0.800000        3\n",
      "3         cat   0.964286  0.981818  0.972973       55\n",
      "4        goat   0.848485  0.717949  0.777778       78\n",
      "5    roe deer   0.906077  0.976190  0.939828      336\n",
      "6         dog   0.812500  0.900990  0.854460      101\n",
      "7    squirrel   0.800000  0.800000  0.800000        5\n",
      "8       equid   0.945783  0.862637  0.902299      182\n",
      "9   lagomorph   1.000000  1.000000  1.000000       11\n",
      "10       wolf   0.913386  0.920635  0.916996      126\n",
      "11       lynx   0.994350  0.956522  0.975069      184\n",
      "12      sheep   0.979339  0.983402  0.981366      241\n",
      "13   mustelid   1.000000  0.809524  0.894737       21\n",
      "14       bird   1.000000  0.933884  0.965812      121\n",
      "15       bear   0.977366  0.903042  0.938735      526\n",
      "16        fox   0.897638  0.977143  0.935705      350\n",
      "17  wild boar   0.941399  0.965116  0.953110      516\n",
      "18        cow   0.684211  0.866667  0.764706       30\n",
      "19    overall   0.920914  0.903535  0.908297     3557\n",
      "Running inference for model: ../models/Best Oveall Loss Model - deepfaune-finetuned-3epochs-lr1e-5.pt\n",
      "Running inference on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on validation set with model ../models/Best Oveall Loss Model - deepfaune-finetuned-3epochs-lr1e-5.pt: 100%|██████████| 3669/3669 [01:17<00:00, 47.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference on test set with model ../models/Best Oveall Loss Model - deepfaune-finetuned-3epochs-lr1e-5.pt: 100%|██████████| 3557/3557 [01:15<00:00, 47.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for validation set...\n",
      "Calculating metrics for test set...\n",
      "\n",
      "Metrics for model ../models/Best Oveall Loss Model - deepfaune-finetuned-3epochs-lr1e-5.pt on validation set:\n",
      "        class  precision    recall        f1  support\n",
      "0      badger   0.919355  0.966102  0.942149       59\n",
      "1    red deer   0.968595  0.927215  0.947454      632\n",
      "2     chamois   1.000000  1.000000  1.000000        4\n",
      "3         cat   0.960000  0.960000  0.960000       25\n",
      "4        goat   0.849162  0.921212  0.883721      165\n",
      "5    roe deer   0.946067  0.948198  0.947132      444\n",
      "6         dog   0.908333  0.947826  0.927660      115\n",
      "7    squirrel   0.888889  1.000000  0.941176        8\n",
      "8       equid   1.000000  0.760000  0.863636       50\n",
      "9   lagomorph   1.000000  0.933333  0.965517       15\n",
      "10       wolf   0.872340  0.953488  0.911111       86\n",
      "11       lynx   0.986301  0.964286  0.975169      224\n",
      "12      sheep   0.979253  0.983333  0.981289      240\n",
      "13   mustelid   1.000000  0.870968  0.931034       31\n",
      "14       bird   0.959016  0.951220  0.955102      123\n",
      "15       bear   0.956647  0.940341  0.948424      352\n",
      "16        fox   0.948485  0.954268  0.951368      328\n",
      "17  wild boar   0.948158  0.988620  0.967967      703\n",
      "18        cow   0.821429  0.707692  0.760331       65\n",
      "19    overall   0.942739  0.930426  0.934749     3669\n",
      "\n",
      "Metrics for model ../models/Best Oveall Loss Model - deepfaune-finetuned-3epochs-lr1e-5.pt on test set:\n",
      "        class  precision    recall        f1  support\n",
      "0      badger   0.841270  1.000000  0.913793       53\n",
      "1    red deer   0.981758  0.957929  0.969697      618\n",
      "2     chamois   1.000000  0.666667  0.800000        3\n",
      "3         cat   0.981481  0.963636  0.972477       55\n",
      "4        goat   0.820896  0.705128  0.758621       78\n",
      "5    roe deer   0.940171  0.982143  0.960699      336\n",
      "6         dog   0.771930  0.871287  0.818605      101\n",
      "7    squirrel   1.000000  1.000000  1.000000        5\n",
      "8       equid   0.944099  0.835165  0.886297      182\n",
      "9   lagomorph   1.000000  0.909091  0.952381       11\n",
      "10       wolf   0.951613  0.936508  0.944000      126\n",
      "11       lynx   0.961749  0.956522  0.959128      184\n",
      "12      sheep   0.983333  0.979253  0.981289      241\n",
      "13   mustelid   0.950000  0.904762  0.926829       21\n",
      "14       bird   1.000000  0.975207  0.987448      121\n",
      "15       bear   0.989035  0.857414  0.918534      526\n",
      "16        fox   0.933702  0.965714  0.949438      350\n",
      "17  wild boar   0.890653  0.978682  0.932595      516\n",
      "18        cow   0.508772  0.966667  0.666667       30\n",
      "19    overall   0.918445  0.916409  0.910447     3557\n",
      "Saving all results to ../data/all_model_metrics.xlsx...\n",
      "All results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/trr26/miniconda3/envs/camera_traps/lib/python3.11/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "/home/users/trr26/miniconda3/envs/camera_traps/lib/python3.11/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n",
      "/home/users/trr26/miniconda3/envs/camera_traps/lib/python3.11/site-packages/openpyxl/workbook/child.py:99: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "# Function to run inference and store predictions\n",
    "def run_inference_and_store_predictions(model_path, data_loader, dataset_type):\n",
    "    results = {'preds': [], 'probs': [], 'labels': [], 'images': []}\n",
    "    classifier = Classifier(model_path)\n",
    "    \n",
    "    for images, labels in tqdm(data_loader, desc=f\"Running inference on {dataset_type} set with model {model_path}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        for i in range(images.size(0)):\n",
    "            pred_class, pred_prob = classifier.predict(images[i])\n",
    "            results['preds'].append(pred_class)\n",
    "            results['probs'].append(pred_prob)\n",
    "            results['labels'].append(labels[i].item())\n",
    "            results['images'].append(data_loader.dataset.images[i])\n",
    "                \n",
    "    return results\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(results):\n",
    "    y_true = results['labels']\n",
    "    y_pred = results['preds']\n",
    "    \n",
    "    # Filter out classes with no true samples\n",
    "    present_classes = [i for i in range(len(ANIMAL_CLASSES)) if i in y_true or i in y_pred]\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=None, labels=present_classes, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=None, labels=present_classes, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, labels=present_classes, zero_division=0)\n",
    "    support = np.bincount(y_true, minlength=len(ANIMAL_CLASSES))[present_classes]\n",
    "    \n",
    "    overall_precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    overall_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    metrics = {\n",
    "        'class': [ANIMAL_CLASSES[i] for i in present_classes] + ['overall'],\n",
    "        'precision': np.append(precision, overall_precision),\n",
    "        'recall': np.append(recall, overall_recall),\n",
    "        'f1': np.append(f1, overall_f1),\n",
    "        'support': np.append(support, len(y_true))\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Create empty DataFrames for each model\n",
    "val_metrics_dfs = {}\n",
    "test_metrics_dfs = {}\n",
    "\n",
    "# Iterate over each model and run inference on both validation and test sets\n",
    "for model_path in MODEL_PATHS:\n",
    "    print(f\"Running inference for model: {model_path}\")\n",
    "    \n",
    "    # Run inference on validation set\n",
    "    print(\"Running inference on validation set...\")\n",
    "    val_results = run_inference_and_store_predictions(model_path, val_loader, 'validation')\n",
    "    # Run inference on test set\n",
    "    print(\"Running inference on test set...\")\n",
    "    test_results = run_inference_and_store_predictions(model_path, test_loader, 'test')\n",
    "\n",
    "    # Calculate and print metrics\n",
    "    print(\"Calculating metrics for validation set...\")\n",
    "    val_metrics = calculate_metrics(val_results)\n",
    "    print(\"Calculating metrics for test set...\")\n",
    "    test_metrics = calculate_metrics(test_results)\n",
    "    \n",
    "    print(f\"\\nMetrics for model {model_path} on validation set:\")\n",
    "    val_metrics_df = pd.DataFrame(val_metrics)\n",
    "    print(val_metrics_df)\n",
    "    print(f\"\\nMetrics for model {model_path} on test set:\")\n",
    "    test_metrics_df = pd.DataFrame(test_metrics)\n",
    "    print(test_metrics_df)\n",
    "    \n",
    "    # Store results in DataFrames for further analysis\n",
    "    val_metrics_dfs[model_path] = val_metrics_df\n",
    "    test_metrics_dfs[model_path] = test_metrics_df\n",
    "\n",
    "# Save all results to a new Excel file for further analysis\n",
    "all_results_file = \"../data/all_model_metrics.xlsx\"\n",
    "print(f\"Saving all results to {all_results_file}...\")\n",
    "with pd.ExcelWriter(all_results_file) as writer:\n",
    "    for model_path in MODEL_PATHS:\n",
    "        val_metrics_df = val_metrics_dfs[model_path]\n",
    "        test_metrics_df = test_metrics_dfs[model_path]\n",
    "        combined_metrics_df = val_metrics_df.join(test_metrics_df.set_index('class'), on='class', rsuffix='_test')\n",
    "        sheet_name = os.path.basename(model_path)\n",
    "        combined_metrics_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "print(\"All results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camera_traps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
