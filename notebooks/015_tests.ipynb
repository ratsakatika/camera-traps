{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import timm\n",
    "import requests\n",
    "import email\n",
    "import imaplib\n",
    "import time\n",
    "import re\n",
    "import io\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from megadetector.detection import run_detector\n",
    "from megadetector.visualization import visualization_utils as vis_utils\n",
    "\n",
    "# Load settings from configuration file\n",
    "with open('../config.yaml') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "IMAP_HOST = config['imap_config']['host']\n",
    "EMAIL_USER = config['imap_config']['user']\n",
    "EMAIL_PASS = config['imap_config']['password']\n",
    "TELEGRAM_BOT_TOKEN = config['telegram_config']['bot_token']\n",
    "TELEGRAM_CHAT_ID = '-1002249589791' # replace with config after tests\n",
    "\n",
    "# Detection and Classification Model Settings\n",
    "MODEL_PATH_DETECTOR = '../models/md_v5a.0.0.pt'\n",
    "MODEL_PATH_CLASSIFIER = '../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt'\n",
    "BACKBONE = 'vit_large_patch14_dinov2'\n",
    "ANIMAL_CLASSES = [\"badger\", \"ibex\", \"red deer\", \"chamois\", \"cat\", \"goat\", \"roe deer\", \"dog\", \"squirrel\", \"equid\", \"genet\", \"hedgehog\", \"lagomorph\", \"wolf\", \"lynx\", \"marmot\", \"micromammal\", \"mouflon\", \"sheep\", \"mustelid\", \"bird\", \"bear\", \"nutria\", \"fox\", \"wild boar\", \"cow\"]\n",
    "DETECTOR_CLASSES = [\"animal\", \"human\", \"vehicle\"]\n",
    "species_of_interest = {\"wild boar\", \"bear\", \"wolf\", \"roe deer\", \"red deer\"}\n",
    "DETECTION_THRESHOLD = 0.05\n",
    "CLASSIFICATION_THRESHOLD = 0.05\n",
    "\n",
    "# Load the MegaDetector model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "detector = run_detector.load_detector(MODEL_PATH_DETECTOR)\n",
    "\n",
    "# move to utils.py\n",
    "\n",
    "class Classifier:\n",
    "    \"\"\"Image classifier for animal species.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model = timm.create_model(BACKBONE, pretrained=False, num_classes=len(ANIMAL_CLASSES))\n",
    "        state_dict = torch.load(MODEL_PATH_CLASSIFIER, map_location=torch.device(device))['state_dict']\n",
    "        self.model.load_state_dict({k.replace('base_model.', ''): v for k, v in state_dict.items()})\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((518, 518), interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, image):\n",
    "        \"\"\"Predict the species of an animal in the image.\"\"\"\n",
    "        img_tensor = self.transforms(image).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(img_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            top_p, top_class = probabilities.topk(1, dim=1)\n",
    "            return ANIMAL_CLASSES[top_class.item()], top_p.item()\n",
    "        \n",
    "def image_to_bytes(image):\n",
    "    \"\"\"Convert an image to bytes.\"\"\"\n",
    "    byte_arr = io.BytesIO()\n",
    "    image.save(byte_arr, format='JPEG')\n",
    "    byte_arr.seek(0)\n",
    "    return byte_arr\n",
    "\n",
    "def detector(image):\n",
    "    \"\"\"Run the MegaDetector on an image and return detections above the threshold.\"\"\"\n",
    "    processed_image = vis_utils.load_image(image_to_bytes(image))\n",
    "    result = model.generate_detections_one_image(processed_image)\n",
    "    detections_above_threshold = [d for d in result['detections'] if d['conf'] > DETECTION_THRESHOLD]\n",
    "    return detections_above_threshold\n",
    "\n",
    "\n",
    "\n",
    "# Initialize classifier\n",
    "classifier = Classifier()\n",
    "\n",
    "def load_font(font_path, font_size):\n",
    "    \"\"\"Load the specified font.\"\"\"\n",
    "    try:\n",
    "        return ImageFont.truetype(font_path, font_size)\n",
    "    except IOError:\n",
    "        return ImageFont.load_default()\n",
    "\n",
    "def annotate_image(image, detections, classifier, species_of_interest, font):\n",
    "    \"\"\"Annotate the image with detection results.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    detection_results = []\n",
    "    species_counts = {species: 0 for species in ANIMAL_CLASSES}\n",
    "    highest_confidences = {species: 0 for species in ANIMAL_CLASSES}\n",
    "\n",
    "    for i, detection in enumerate(detections):\n",
    "        bbox = detection['bbox']\n",
    "        left, top, width, height = bbox\n",
    "        left_resized = int(left * image.width)\n",
    "        top_resized = int(top * image.height)\n",
    "        right_resized = int((left + width) * image.width)\n",
    "        bottom_resized = int((top + height) * image.height)\n",
    "\n",
    "        cropped_image = image.crop((left_resized, top_resized, right_resized, bottom_resized))\n",
    "        species, confidence = classifier.predict(cropped_image)\n",
    "        if confidence > CLASSIFICATION_THRESHOLD:\n",
    "            detection_results.append((species, confidence, bbox))\n",
    "            species_counts[species] += 1\n",
    "            highest_confidences[species] = max(highest_confidences[species], confidence)\n",
    "\n",
    "            # Draw bounding box and label\n",
    "            draw.rectangle([left_resized, top_resized, right_resized, bottom_resized], outline=\"red\", width=4)\n",
    "            if species in species_of_interest:\n",
    "                label = f\"{species.title()}: {int(confidence * 100)}%\"\n",
    "                text_bbox = draw.textbbox((left_resized, top_resized), label, font=font)\n",
    "                draw.rectangle(text_bbox, fill=\"red\")\n",
    "                draw.text((left_resized, top_resized), label, fill=\"white\", font=font)\n",
    "\n",
    "    return detection_results, species_counts, highest_confidences\n",
    "\n",
    "def generate_caption(species_of_interest_detected, species_counts, highest_confidences, capture_time):\n",
    "    \"\"\"Generate a caption for the image.\"\"\"\n",
    "    if species_of_interest_detected:\n",
    "        highest_confidence_species = max(species_of_interest_detected, key=species_of_interest_detected.get)\n",
    "        count_highest_confidence_species = species_of_interest_detected[highest_confidence_species]\n",
    "        caption = f\"{count_highest_confidence_species} {highest_confidence_species.upper()} DETECTED\\n\"\n",
    "    else:\n",
    "        highest_confidence_species = None\n",
    "        caption = \"NO SPECIES OF INTEREST DETECTED\\n\"\n",
    "\n",
    "    caption += \"Location: TBC\\n\"\n",
    "    caption += f\"Time: {capture_time}\\n\"\n",
    "    caption += \"------------------------\\n\"\n",
    "    caption += \"Further information:\\n\"\n",
    "\n",
    "    sorted_by_detections = sorted([(species, count, highest_confidences[species]) for species, count in species_counts.items() if count > 0], key=lambda x: x[1], reverse=True)\n",
    "    for species, count, max_conf in sorted_by_detections[:2]:\n",
    "        caption += f\"{species.title()}: {count} detections, highest confidence {int(max_conf * 100)}%\\n\"\n",
    "\n",
    "    return caption, highest_confidence_species\n",
    "\n",
    "def save_image_with_metadata(image, highest_confidence_species):\n",
    "    \"\"\"Save the image with metadata.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    species_name = highest_confidence_species.replace(' ', '_') if highest_confidence_species else \"no_species_of_interest\"\n",
    "    file_path = f\"../data/{timestamp}-{species_name}.jpg\"\n",
    "    image.save(file_path)\n",
    "    return file_path\n",
    "\n",
    "def process_single_image(image):\n",
    "    \"\"\"Process a single image for detection and classification.\"\"\"\n",
    "    saved_image = image.copy()\n",
    "    annotated_image = image.copy()\n",
    "    font = load_font(\"Carlito-Bold.ttf\", 100)\n",
    "\n",
    "    # Detect objects in the image\n",
    "    detections = detector(image)\n",
    "    print(f\"{len(detections)} detections.\")\n",
    "\n",
    "    if detections:\n",
    "        # Annotate the image\n",
    "        detection_results, species_counts, highest_confidences = annotate_image(annotated_image, detections, classifier, species_of_interest, font)\n",
    "\n",
    "        # Generate caption\n",
    "        species_of_interest_detected = {species: species_counts[species] for species in species_of_interest if species_counts[species] > 0}\n",
    "        try:\n",
    "            exif_data = image._getexif()\n",
    "            capture_time_exif = exif_data.get(36867)\n",
    "            capture_time = datetime.strptime(capture_time_exif, \"%Y:%m:%d %H:%M:%S\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except (AttributeError, TypeError):\n",
    "            capture_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        caption, highest_confidence_species = generate_caption(species_of_interest_detected, species_counts, highest_confidences, capture_time)\n",
    "\n",
    "        # Save the image\n",
    "        save_image_with_metadata(saved_image, highest_confidence_species)\n",
    "\n",
    "        return annotated_image, caption\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def send_photo_to_telegram(bot_token, chat_id, photo, caption):\n",
    "    \"\"\"Send photo with caption to Telegram.\"\"\"\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendPhoto\"\n",
    "    with io.BytesIO() as buf:\n",
    "        photo.save(buf, format='JPEG')\n",
    "        buf.seek(0)\n",
    "        files = {'photo': buf}\n",
    "        params = {'chat_id': chat_id, 'caption': caption}\n",
    "        response = requests.post(url, files=files, data=params)\n",
    "        response.raise_for_status()\n",
    "        print(\"Alert sent.\")\n",
    "\n",
    "def download_image_from_url(url):\n",
    "    \"\"\"Download an image from a URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return Image.open(io.BytesIO(response.content))\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading image from {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_images_from_email(msg):\n",
    "    \"\"\"Extract images from an email message.\"\"\"\n",
    "    image_list = []\n",
    "    if msg.is_multipart():\n",
    "        for part in msg.walk():\n",
    "            content_type = part.get_content_type()\n",
    "            content_disposition = part.get('Content-Disposition', '')\n",
    "\n",
    "            if content_type.startswith('image/') and 'attachment' in content_disposition:\n",
    "                image_data = part.get_payload(decode=True)\n",
    "                image = Image.open(io.BytesIO(image_data))\n",
    "                image_list.append(image)\n",
    "            elif content_type == 'text/html':\n",
    "                html_body = part.get_payload(decode=True).decode()\n",
    "                image_urls = re.findall(r'<img src=\"(https?://[^\"]+)\"', html_body)\n",
    "                for url in image_urls:\n",
    "                    image = download_image_from_url(url)\n",
    "                    if image:\n",
    "                        image_list.append(image)\n",
    "    return image_list\n",
    "\n",
    "def check_emails():\n",
    "    \"\"\"Check emails for new messages with images.\"\"\"\n",
    "    mail = imaplib.IMAP4_SSL(IMAP_HOST)\n",
    "    mail.login(EMAIL_USER, EMAIL_PASS)\n",
    "    mail.select('inbox')\n",
    "    typ, data = mail.search(None, 'UNSEEN')\n",
    "    for num in data[0].split():\n",
    "        typ, data = mail.fetch(num, '(RFC822)')\n",
    "        msg = email.message_from_bytes(data[0][1])\n",
    "        images = extract_images_from_email(msg)\n",
    "        for index, image in enumerate(images):\n",
    "            processed_image, caption = process_single_image(image)\n",
    "            if processed_image:\n",
    "                send_photo_to_telegram(TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID, processed_image, caption)\n",
    "    mail.logout()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Monitoring {EMAIL_USER} for new messages...\")\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            check_emails()\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted by user\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(f\"\\nMonitoring {EMAIL_USER} for new messages...\")\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
