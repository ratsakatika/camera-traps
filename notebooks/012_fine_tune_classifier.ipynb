{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 1234/4334 [12:51<32:12,  1.60it/s]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import InterpolationMode, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "CROP_SIZE = 182\n",
    "BACKBONE = \"vit_large_patch14_dinov2\"\n",
    "weight_path = \"../models/fine-tuned-deepfaune-vit_large_patch14_dinov2.lvd142m.pt\"\n",
    "train_path = \"/media/tom-ratsakatika/CRUCIAL 4TB/FCC Camera Trap Data/split_data/train\"\n",
    "val_path = \"/media/tom-ratsakatika/CRUCIAL 4TB/FCC Camera Trap Data/split_data/val\"\n",
    "test_path = \"/media/tom-ratsakatika/CRUCIAL 4TB/FCC Camera Trap Data/split_data/test\"\n",
    "\n",
    "ANIMAL_CLASSES = [\"badger\", \"ibex\", \"red deer\", \"chamois\", \"cat\", \"goat\", \"roe deer\", \"dog\", \"squirrel\", \"equid\", \"genet\",\n",
    "                  \"hedgehog\", \"lagomorph\", \"wolf\", \"lynx\", \"marmot\", \"micromammal\", \"mouflon\",\n",
    "                  \"sheep\", \"mustelid\", \"bird\", \"bear\", \"nutria\", \"fox\", \"wild boar\", \"cow\"]\n",
    "\n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for label in os.listdir(directory):\n",
    "            label_dir = os.path.join(directory, label)\n",
    "            if os.path.isdir(label_dir):\n",
    "                for image in os.listdir(label_dir):\n",
    "                    self.images.append(os.path.join(label_dir, image))\n",
    "                    self.labels.append(ANIMAL_CLASSES.index(label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, freeze_up_to_layer=16):\n",
    "        super(Classifier, self).__init__()\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = timm.create_model(BACKBONE, pretrained=False, num_classes=len(ANIMAL_CLASSES), dynamic_img_size=True)\n",
    "        state_dict = torch.load(weight_path, map_location=torch.device(device))['state_dict']\n",
    "        self.model.load_state_dict({k.replace('base_model.', ''): v for k, v in state_dict.items()})\n",
    "\n",
    "        # Freeze layers up to the specified layer\n",
    "        if freeze_up_to_layer is not None:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if self._should_freeze_layer(name, freeze_up_to_layer):\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize(size=(CROP_SIZE, CROP_SIZE), interpolation=InterpolationMode.BICUBIC, max_size=None, antialias=None),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
    "        ])\n",
    "\n",
    "    def _should_freeze_layer(self, name, freeze_up_to_layer):\n",
    "        if 'blocks' in name:\n",
    "            block_num = int(name.split('.')[1])\n",
    "            if block_num <= freeze_up_to_layer:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict(self, image):\n",
    "        img_tensor = self.transforms(image).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(img_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            top_p, top_class = probabilities.topk(1, dim=1)\n",
    "            return ANIMAL_CLASSES[top_class.item()], top_p.item()\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return running_loss / len(dataloader), accuracy\n",
    "\n",
    "def test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def main():\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    num_epochs = 10  # Set the number of epochs\n",
    "    batch_size = 4  # Set the batch size\n",
    "    learning_rate = 1e-5  # Reduced learning rate for fine-tuning\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((CROP_SIZE, CROP_SIZE), interpolation=InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
    "    ])\n",
    "\n",
    "    print('Loading training data...')\n",
    "    train_dataset = AnimalDataset(train_path, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = Classifier(freeze_up_to_layer=16).to(device)  # Freeze up to the 16th layer\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print('Training started...')\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss}')\n",
    "\n",
    "    # Load validation data only when needed\n",
    "    print('Calculating validation loss...')\n",
    "    val_dataset = AnimalDataset(val_path, transform=transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
    "    print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}%')\n",
    "\n",
    "    # Load test data only when needed\n",
    "    print('Testing the model...')\n",
    "    test_dataset = AnimalDataset(test_path, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_accuracy = test(model, test_loader, device)\n",
    "    print(f'Test Accuracy: {test_accuracy}%')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
