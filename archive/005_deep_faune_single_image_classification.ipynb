{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw \n",
    "import cv2 \n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import InterpolationMode, transforms\n",
    "import timm\n",
    "from IPython.display import display\n",
    "\n",
    "# Define classes\n",
    "txt_animalclasses = {\n",
    "    'en': [\"badger\", \"ibex\", \"red deer\", \"chamois\", \"cat\", \"goat\", \"roe deer\", \"dog\", \"squirrel\", \"equid\", \"genet\",\n",
    "           \"hedgehog\", \"lagomorph\", \"wolf\", \"lynx\", \"marmot\", \"micromammal\", \"mouflon\",\n",
    "           \"sheep\", \"mustelid\", \"bird\", \"bear\", \"nutria\", \"fox\", \"wild boar\", \"cow\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.model = YOLO('../models/deepfaune-yolov8s_960.pt')\n",
    "\n",
    "    def bestBoxDetection(self, imagecv):\n",
    "        image_rgb = cv2.cvtColor(imagecv, cv2.COLOR_BGR2RGB)\n",
    "        image_pil = Image.fromarray(image_rgb)\n",
    "        resized_image = image_pil.resize((960, 960), Image.Resampling.LANCZOS)\n",
    "        results = self.model(resized_image)\n",
    "\n",
    "        if not results or not results[0].boxes or results[0].boxes.data.shape[0] == 0:\n",
    "            return None, 0, np.zeros(4), 0, None\n",
    "\n",
    "        detections = results[0].boxes.data\n",
    "        best_detection = detections[detections[:, 4].argmax()]\n",
    "        xmin, ymin, xmax, ymax, conf, cls_id = best_detection[:6]\n",
    "        box = [int(xmin), int(ymin), int(xmax), int(ymax)]\n",
    "        cropped_image = resized_image.crop(box)\n",
    "        return cropped_image, int(cls_id), box, conf, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, device):\n",
    "        self.model = self.load_model('../models/deepfaune-vit_large_patch14_dinov2.lvd142m.pt', device)\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize((182, 182), interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def load_model(self, model_path, device):\n",
    "        model = timm.create_model('vit_large_patch14_dinov2', pretrained=False, num_classes=len(txt_animalclasses['en']), dynamic_img_size=True)\n",
    "        state_dict = torch.load(model_path, map_location=torch.device(device))['state_dict']\n",
    "        adjusted_state_dict = {k.replace('base_model.', ''): v for k, v in state_dict.items() if 'base_model.' in k}\n",
    "        model.load_state_dict(adjusted_state_dict)\n",
    "        return model\n",
    "\n",
    "    def predict(self, image):\n",
    "        img_tensor = self.transforms(image).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(img_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            top_p, top_class = probabilities.topk(1, dim=1)\n",
    "            return txt_animalclasses['en'][top_class.item()], top_p.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(cropped_image, label, confidence):\n",
    "    draw = ImageDraw.Draw(cropped_image)\n",
    "    text = f\"{label} ({confidence*100:.0f}%)\"\n",
    "    draw.text((10, 10), text, fill=\"red\")\n",
    "    display(cropped_image)\n",
    "\n",
    "def process_single_image(image_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    image = Image.open(image_path)\n",
    "    imagecv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    detector = Detector()\n",
    "    classifier = Classifier(device)\n",
    "    cropped_image, category, box, conf, _ = detector.bestBoxDetection(imagecv)\n",
    "\n",
    "    if cropped_image is not None:\n",
    "        animal_type, confidence = classifier.predict(cropped_image)\n",
    "        print(f\"{device}: Detection with confidence {conf:.3f}, Classification of {animal_type} with confidence {confidence:.3f}\")\n",
    "        visualize_detection(cropped_image, animal_type, confidence)\n",
    "    else:\n",
    "        print(\"No object detected.\")\n",
    "\n",
    "current_image_path = \"/home/tom-ratsakatika/Downloads/maybe a fox.jpg\"\n",
    "\n",
    "process_single_image(current_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camera-traps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
